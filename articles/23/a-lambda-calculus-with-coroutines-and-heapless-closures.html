

<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?" />

<link rel="alternate" type="application/atom+xml" title="cc - Ayaz Hafiz" href="/feed-rrs2.xml">


<title>
  
    A Lambda Calculus With Coroutines and Heapless, Directly-Called Closures
  
</title>
<meta name="description" content="co_lc is a lambda calculus extended with stackful coroutines. An efficient implementation for the compilation and virtual machine execution of co_lc is presented. The implementation supports tail-call optimization and eliminates all indirect calls by defunctionalizing closures." />

<link
  rel="canonical"
  href="/articles/23/a-lambda-calculus-with-coroutines-and-heapless-closures"
/>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    TeX: {
      Macros: {
        co: "\\colon",
        msf: "\\mathsf",
        Ra: "\\Rightarrow",
        Def: "\\text{Definition.}",
        Thm: "\\text{Theorem.}",
        Pf: "\\text{Proof.}",
        eps: "\\epsilon",
        lam: "\\lambda",
        lt: "<",
        
        1: "\\unicode{x1D7D9}",
        
        2: "\\unicode{x1D7DA}",
        
      },
    }
  });
  MathJax.Hub.Queue(function () {
    document.body.setAttribute('render-done', '');
  });
</script>

<script
  type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
></script>

<link
  rel="stylesheet"
  type="text/css"
  href="/css/shiki.css?1676911955025339700"
/>




    <link
      rel="stylesheet"
      type="text/css"
      href="/css/post.css?1676911955025339700"
    />
  </head>

  <style></style>

  <body>
    <div class="container post">
      <div class="panel">
        <div class="column-right A lambda calculus with coroutines and heapless, directly-called closures-main">
          <section class="nav">
  <a class="nav-link" href="/about">about</a
  ><a class="nav-link" href="/cc">cc</a
  ><a class="nav-link" href="/visual">visual</a>
</section>
 <h1 class="title">A Lambda Calculus With Coroutines and Heapless, Directly-Called Closures</h1>
<p class="byline">February 18, 2023</p>

<article class="post">
   <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#introduction">Introduction</a></li>
<li class="toc-entry toc-h2"><a href="#source-language">Source language</a></li>
<li class="toc-entry toc-h2"><a href="#virtual-machine-strategy">Virtual machine strategy</a>
<ul>
<li class="toc-entry toc-h3"><a href="#representing-function-frames">Representing function frames</a></li>
<li class="toc-entry toc-h3"><a href="#representing-function-calls">Representing function calls</a></li>
<li class="toc-entry toc-h3"><a href="#representing-fibers">Representing fibers</a></li>
<li class="toc-entry toc-h3"><a href="#representing-tuples">Representing tuples</a></li>
<li class="toc-entry toc-h3"><a href="#instruction-set">Instruction set</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#compilation-strategy">Compilation strategy</a>
<ul>
<li class="toc-entry toc-h3"><a href="#type-inference">Type inference</a>
<ul>
<li class="toc-entry toc-h4"><a href="#a-tip-for-inference-of-tuples">A tip for inference of tuples</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#eliminating-indirect-calls-and-heap-allocated-closures-via-defunctionalization">Eliminating indirect calls and heap-allocated closures via defunctionalization</a>
<ul>
<li class="toc-entry toc-h4"><a href="#why-does-eliminating-indirect-calls-matter%3F">Why does eliminating indirect calls matter?</a>
<ul>
<li class="toc-entry toc-h5"><a href="#function-pointers">Function pointers</a></li>
<li class="toc-entry toc-h5"><a href="#conditionally-determined-functions">Conditionally-determined functions</a></li>
</ul>
</li>
<li class="toc-entry toc-h4"><a href="#eliminating-heap-allocated-captures">Eliminating heap-allocated captures</a></li>
<li class="toc-entry toc-h4"><a href="#inference-and-compilation-semantics-of-lambda-sets">Inference and compilation semantics of lambda sets</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#compiling-functions%2C-including-lambda-sets">Compiling functions, including lambda sets</a></li>
<li class="toc-entry toc-h3"><a href="#tip%3A-deciding-where-to-store-values">Tip: deciding where to store values</a>
<ul>
<li class="toc-entry toc-h4"><a href="#tail-call-optimization">Tail-call optimization</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#unexplored-extensions">Unexplored extensions</a></li>
<li class="toc-entry toc-h2"><a href="#playground-%26-implementation">Playground &amp; Implementation</a></li>
<li class="toc-entry toc-h2"><a href="#ad%3A-are-you-interested-in-compiling-structural-subtypes%3F">Ad: Are you interested in compiling structural subtypes?</a></li>
</ul> 
  <p>In this cc, I'd like to present a small language based on the lambda calculus
exetended with stackful coroutines. I'll discuss a virtual machine designed for
the language's execution, and an efficient compilation scheme.</p>
<p>We'll see that the compilation scheme</p>
<ul>
<li>naturally supports tail-call optimization</li>
<li>eliminates all heap allocation of closures</li>
<li>eliminates the need for indirect calls</li>
</ul>
<p>without restriction of the language's expressiveness - which may be interesting in its own right.</p>
<p>This post is intended for anyone broadly interested in implementing coroutines,
compilers, or virtual machines. I am not an expert in any of those, but I hope
that something in this post may be useful to you. The post will assume basic
familiarity with unification-based type inference and code generation schemes.</p>
<p>First, let you let me show you a <a href="https://ayazhafiz.com/plts/playground/co_lc/?input=DYUwLgBATiDGEDMCWAjCBeCAdAdhAtAHwBQEEAnkiMACYDcpESCEeAPBAEyNgAWIeHI2oBnEBAAUyNBLz4IARgCUSiAGpJ0yXK4riSIcVCQY8EAA84GbCLABDMOKKNbDiK8cA6AAyMAPhAABgAKAjQGAOYEJGRkxoioCtYwIgCuALbiHiA%2BTEKxEBZWAN7SCgA0EN6V2Z6c6ooAvv5BACIA9jjicoQQxbXVrDX2XpzNBkbg0Kk4AGKo1iIADnYA7nhSC5zeqhPxKanAkJhF8MVQM-MolYPejXnExADEXN44fAkonXawsEisGRQICglRwgOBEHaLAO6SWYCQnRExHOIDSR08FWgqMOYDqjSAA&amp;backend=ir&amp;options=NohEFMFsEsBdQDQG9QDcCGAbAruUAuUABwCdoA7eBUAeyNmhvIGcDhizLEJN0AjUAF0AvoMEIwUOIhQYceQqQpVa9RizYdl3cLwEixgoA">playground</a> exemplifying the language and its
compiler/VM. You can hover over values in the input buffer of the playground to
see inferred types. The default program comes from <a href="https://cyberscript.dev/play.html#">Cyber's playground</a>,
computing the 20th fibonacci number, and how many times <code>fib</code> was called.</p>
<figure class="fullwidth notes-fullwidth resp-iframe-container" style="margin-top:2em;height:10vh">
  <iframe class="resp-iframe" src="https://ayazhafiz.com/plts/playground/co_lc/?input=DYUwLgBATiDGEDMCWAjCBeCAdAdhAtAHwBQEEAnkiMACYDcpESCEeAPBAEyNgAWIeHI2oBnEBAAUyNBLz4IARgCUSiAGpJ0yXK4riSIcVCQY8EAA84GbCLABDMOKKNbDiK8cA6AAyMAPhAABgAKAjQGAOYEJGRkxoioCtYwIgCuALbiHiA%2BTEKxEBZWAN7SCgA0EN6V2Z6c6ooAvv5BACIA9jjicoQQxbXVrDX2XpzNBkbg0Kk4AGKo1iIADnYA7nhSC5zeqhPxKanAkJhF8MVQM-MolYPejXnExADEXN44fAkonXawsEisGRQICglRwgOBEHaLAO6SWYCQnRExHOIDSR08FWgqMOYDqjSAA&backend=ir&options=NohEFMFsEsBdQDQG9QDcCGAbAruUAuUABwCdoA7eBUAeyNmhvIGcDhizLEJN0AjUAF0AvoMEIwUOIhQYceQqQpVa9RizYdl3cLwEixgoA" allowtransparency="true" frameborder="0"></iframe>
</figure>
<h2 id="introduction" tabindex="-1"><a class="header-anchor" href="#introduction" aria-hidden="true"></a>Introduction</h2>
<p>Recently, I've been studying the efficient implementation of <a href="https://effekt-lang.org/docs/concepts/effect-handlers">effect
handler</a>, which I
currently believe are the most promising avenue for the future of managed
effects in programming languages.</p>
<p>Effect handlers have a lot to do with coroutines - in fact, one way to implement
effect handlers is as stackful coroutines, <a href="https://v2.ocaml.org/manual/effects.html#s:effects-fibers">like OCaml does</a>.</p>
<details>
<summary>
In this cc, I'll use the terms "coroutine", "green thread", and "fiber" all to
refer to the specific idea of first-class, stackful, non-presumptive coroutines.
</summary>
<p>Specifically,</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Coroutine">Coroutines</a> are segments of a
program whose execution can be paused and resumed at-will. They can be thought
of threads of execution controlled in userspace, rather than in the kernel.
<ul>
<li>If you are familiar with goroutines, corotuines are like goroutines, except
that
<ul>
<li>The point at which coroutines are preempted must be explicitly defined by
the programmer; in the language we'll look at below, via the <code>yield</code>
keyword.</li>
<li>Dually, coroutines do not imply a concurrent runtime; it is up the
programmer whether to, and how to, execute coroutines in a concurrent
fashion. In the language we'll look at below, this is done the <code>spawn</code> and
<code>resume</code> keywords.</li>
</ul>
</li>
</ul>
</li>
<li>A <strong>first-class</strong> coroutine can be used like any other value in a language,
unrestricted in its behavior; think of first-class functions.</li>
<li><strong>Stackful</strong> coroutines can arbitrarily pause their execution, including
within nested function calls. Stackful coroutines require a preserved call
stack while they are preserved, <a href="https://blog.varunramesh.net/posts/stackless-vs-stackful-coroutines/">in contrast to stackless
coroutines</a>.
C++ (via <code>co_await</code>/<code>co_yield</code>), Rust (via <code>async</code>/<code>await</code>), and JavaScript
(via <code>async</code>/<code>await</code>) all implement stackless coroutines - with the
restriction that you cannot suspend in nested, non-co-routine call in those
languages. The latter behavior induces the often-named <a href="https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/">function color
problem</a>
for async/await.</li>
<li><strong>Non-presumptive</strong> coroutines are those that cannot be resumed more than
once. In the language we'll discuss below, the <code>resume</code> keyword resumes
execution of a coroutines, and returns a new handle to the coroutine. It is a
runtime error to call <code>resume</code> on the same handle to a coroutine more than
once.</li>
<li>Coroutines are cooperative - unlike threads, which may be preempted
arbitrarily by an operating systems, coroutines require programmer intervention
to specify where execution should be paused and resumed (think <code>async</code>/<code>await</code>
in JavaScript/Python/Rust). Moreoever, coroutines do not imply a concurrent
runtime, and it is up the programmer to define how to execute coroutines.
<ul>
<li>Again, contrast this to goroutines, where the runtime of goroutines is
well-defined and suspension points are largely implicit.</li>
</ul>
</li>
</ul>
</details>
<p>Why am I talking about coroutines here?
I've seen a few good articles discussing implementing coroutines against a
machine-language target
(<a href="https://graphitemaster.github.io/fibers/">1</a>,
<a href="https://cfsamson.gitbook.io/green-threads-explained-in-200-lines-of-rust/">2</a>),
and recent projects like <a href="https://cyberscript.dev">Cyber</a> and
<a href="https://abhinavsarkar.net/posts/implementing-co-1/">Co</a>.
I'd like to present a small model and implementation of coroutines
against a virtual machine target, which may be a nice base for launching more
experiments without designing a programming language intended for general use.</p>
<p><a href="https://abhinavsarkar.net/posts/implementing-co-1/">Co</a> implements coroutines as continuations - which I actually believe
is the most promising technique for an efficient implementation of stackful
coroutines, but I won't expand on that here. Continuations often go hand-in-hand
with closures, which are typically heap-allocated and called
indirectly. To show off something interesting, we'll also have our implementation
compile closures unboxed, and eliminate all indirect calls via
defunctionalization.</p>
<p>Finally, we'll see that tail-call optimization falls out naturally with other
aspects of the implementation.</p>
<p>Okay, let's get started!</p>
<h2 id="source-language" tabindex="-1"><a class="header-anchor" href="#source-language" aria-hidden="true"></a>Source language</h2>
<p>Our source language will be the simply-typed lambda calculus extended with
tuples and fibers. Fibers will be our source-language-level representation of
coroutines, and can be used like any other value. Fibers can be <code>spawn</code>ed,
<code>yield</code>ed, and <code>resume</code>d by the author to enable cooperative multitasking.</p>
<p>As an example, let's consider a program (<a href="https://cyberscript.dev/play.html#">taken from Cyber's
examples</a>) that calculates the 20th
fibonacci number in a fiber that yields to its parent fiber on every iteration.
This usage of <code>yield</code> and <code>resume</code> lets us compute how many times <code>fib</code>
recursively calls itself. I hope you can see how you could run more complicated
tasks concurrently in this style.</p>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class="language-id">ocaml</div><div class='code-container'><code><div class='line'><span style="color: #AF00DB">let</span><span style="color: #000000"> </span><span style="color: #811F3F">rec</span><span style="color: #000000"> </span><span style="color: #795E26">fib</span><span style="color: #000000"> </span><span style="color: #267F99">=</span><span style="color: #000000"> \n </span><span style="color: #811F3F">-&gt;</span></div><div class='line'><span style="color: #000000">  yield</span><span style="color: #811F3F">;</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #AF00DB">if</span><span style="color: #000000"> n </span><span style="color: #811F3F">&lt;</span><span style="color: #000000"> </span><span style="color: #098658">2</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #AF00DB">then</span><span style="color: #000000"> n</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #AF00DB">else</span><span style="color: #000000"> </span><span style="color: #800000">(</span><span style="color: #000000">fib </span><span style="color: #800000">(</span><span style="color: #000000">n </span><span style="color: #811F3F">-</span><span style="color: #000000"> </span><span style="color: #098658">1</span><span style="color: #800000">))</span><span style="color: #000000"> </span><span style="color: #811F3F">+</span><span style="color: #000000"> </span><span style="color: #800000">(</span><span style="color: #000000">fib </span><span style="color: #800000">(</span><span style="color: #000000">n </span><span style="color: #811F3F">-</span><span style="color: #000000"> </span><span style="color: #098658">2</span><span style="color: #800000">))</span></div><div class='line'><span style="color: #000000">in</span></div><div class='line'></div><div class='line'><span style="color: #AF00DB">let</span><span style="color: #000000"> </span><span style="color: #811F3F">rec</span><span style="color: #000000"> </span><span style="color: #795E26">exec</span><span style="color: #000000"> </span><span style="color: #267F99">=</span><span style="color: #000000"> \state </span><span style="color: #811F3F">-&gt;</span></div><div class='line'><span style="color: #000000">  stat state</span><span style="color: #0000FF">.</span><span style="color: #000000">0</span></div><div class='line'><span style="color: #000000">  | `Pending -&gt;</span></div><div class='line'><span style="color: #000000">    let </span><span style="color: #0451A5">fib1</span><span style="color: #000000"> </span><span style="color: #811F3F">=</span><span style="color: #000000"> resume state</span><span style="color: #0000FF">.</span><span style="color: #000000">0 in</span></div><div class='line'><span style="color: #000000">    </span><span style="color: #0451A5">exec</span><span style="color: #000000"> </span><span style="color: #800000">{</span><span style="color: #0451A5">fib1</span><span style="color: #000000">, 0, </span><span style="color: #0451A5">state</span><span style="color: #000000">.2 + 1</span><span style="color: #800000">}</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> `</span><span style="color: #800000">Done</span><span style="color: #000000"> </span><span style="color: #001080">n</span><span style="color: #000000"> </span><span style="color: #267F99">-&gt;</span><span style="color: #000000"> </span><span style="color: #800000">{</span><span style="color: #0451A5">state</span><span style="color: #000000">.0, </span><span style="color: #0451A5">n</span><span style="color: #000000">, </span><span style="color: #0451A5">state</span><span style="color: #000000">.2</span><span style="color: #800000">}</span></div><div class='line'><span style="color: #000000">in</span></div><div class='line'></div><div class='line'><span style="color: #AF00DB">let</span><span style="color: #000000"> </span><span style="color: #795E26">runFib</span><span style="color: #000000"> </span><span style="color: #267F99">=</span><span style="color: #000000"> spawn </span><span style="color: #800000">(</span><span style="color: #000000">fib </span><span style="color: #098658">20</span><span style="color: #800000">)</span><span style="color: #000000"> in</span></div><div class='line'><span style="color: #AF00DB">let</span><span style="color: #000000"> </span><span style="color: #795E26">result</span><span style="color: #000000"> </span><span style="color: #267F99">=</span><span style="color: #000000"> exec </span><span style="color: #800000">{</span><span style="color: #0451A5">runFib</span><span style="color: #000000">, 0, 0</span><span style="color: #800000">}</span><span style="color: #000000"> in</span></div><div class='line'></div><div class='line'><span style="color: #000000">{result.1, result.2}</span></div></code></div></pre>
<p>This language's syntax is very similar to OCaml's. I'll point out a few key
features of its semantics:</p>
<ul>
<li>
<p><code>let rec</code> defines a recursive binding; by default, <code>let</code> bindings are
non-recursive.</p>
</li>
<li>
<p><code>{e1, e2, ..., en}</code> defines a n-ary tuple. Tuple elements are accessed by
0-based indices; for example, <code>t.0</code>.</p>
</li>
<li>
<p>Every program starts on a unique <code>main</code> fiber. A program terminates when the
<code>main</code> fiber termintes, even if other fibers have not terminated<span class="note"><label for="contrast-threads" class="margin-toggle sidenote-number"></label></span><input type="checkbox" id="contrast-threads" class="margin-toggle" /><span class="sidenote">contrast
this to non-joined kernel threads in e.g. C</span>. It's up to the programmer to
decide whether or not all child fibers should terminate<span class="note"><label for="whether-terminate" class="margin-toggle sidenote-number"></label></span><input type="checkbox" id="whether-terminate" class="margin-toggle" /><span class="sidenote">whether this is
a good design design is a different question</span>.</p>
</li>
<li>
<p><code>spawn (fib 20)</code> executes the call <code>fib 20</code> on a new fiber, which can yield to
the parent fiber (in this case the <code>main</code> fiber) arbitrarily. <code>spawn</code> returns
to the calling fiber a handle to the child fiber. These handles have type <code>Fiber</code>.
Fibers have two states - they are either in the pending state, or have
terminated with a value.</p>
</li>
<li>
<p>Fibers can be passed around arbitrarily, including to other fibers. Fibers are
first-class values.</p>
</li>
<li>
<p><code>yield</code> suspends a fiber's execution and returns execution to the current
parent fiber. Note that since fibers can be passed around arbitrarily, the
parent of a fiber may change during a program's execution. <code>yield</code> is a
no-op on the main fiber<span class="note"><label for="yield-noop-warn" class="margin-toggle sidenote-number"></label></span><input type="checkbox" id="yield-noop-warn" class="margin-toggle" /><span class="sidenote">I believe you could
detect <code>yield</code>s that are only reached by the main fiber with a full-program
static analysis, but it's not clear to me whether a more localized analysis
would be suitable.</span>.</p>
</li>
<li>
<p><code>resume</code> returns execution to a child fiber, which executes until its next
<code>yield</code> point or completion. Like <code>spawn</code>, <code>resume</code> returns a <code>Fiber</code>.
It is a runtime to resume the same <code>Fiber</code> twice - in our example above, for
example, it would not be legal to define</p>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class="language-id">diff</div><div class='code-container'><code><div class='line'><span style="color: #A31515">- let fib1 = resume state.0 in</span></div><div class='line'><span style="color: #A31515">- exec {fib1, 0, state.2 + 1}</span></div><div class='line'><span style="color: #098658">+ let _ = resume state.0 in</span></div><div class='line'><span style="color: #098658">+ exec {state.0, 0, state.2 + 1}</span></div></code></div></pre>
<p>A affine type system could enforce this requirement at compile-time, but we
won't discuss that here.</p>
<p>Resuming a completed <code>Fiber</code> is effectively a no-op; the <code>Fiber</code> is
immediately returned as-is.</p>
</li>
<li>
<p>A <code>stat</code> expression queries the state of a <code>Fiber</code>, and matches on a
<code>`Pending</code> branch if the fiber has not yet terminated, or a
<code>`Done</code> branch if it has. The <code>`Done</code> binds the
return value of the fiber to a variable name.</p>
</li>
</ul>
<p>The source language has four types:</p>
<ul>
<li>Integers</li>
<li>Booleans</li>
<li>Tuples composed of the language types, inductively</li>
<li>Fibers composed of the language types, inductively</li>
</ul>
<h2 id="virtual-machine-strategy" tabindex="-1"><a class="header-anchor" href="#virtual-machine-strategy" aria-hidden="true"></a>Virtual machine strategy</h2>
<p>There are a lot of ways you could design a virtual machine for the language
described above. Here, I'll show one design for a <a href="https://en.wikipedia.org/wiki/Stack_machine">stack-based
machine</a>.</p>
<p>First off, let's define the stack part of the stack machine. Suppose that we can
represent all our types as integers<span class="note"><label for="stack-cell-repr" class="margin-toggle sidenote-number"></label></span><input type="checkbox" id="stack-cell-repr" class="margin-toggle" /><span class="sidenote">tuples are just blocks of integers next to
each other, and I'll explain the representation of fibers in a bit</span>; then our
stack is just a dynamically-growing array of integers. For the sake of
simplicity we'll have the stack deal with 64-bit integers, rather than bytes.
This is wasteful, but that's okay for this discussion.</p>
<p>We'll allow a program to arbitrarily push integers onto the stack, pop integers
off the stack, and store integers into arbitrary indices in the stack.</p>
<h3 id="representing-function-frames" tabindex="-1"><a class="header-anchor" href="#representing-function-frames" aria-hidden="true"></a>Representing function frames</h3>
<p>Since a function in our source language might have local variables referenced
multiple times, it'd be nice to support some idea of local variables in the
runtime representation of a function call frame.</p>
<p>The standard approach here is to keep track of a frame pointer in the
runtime, which points to the place that was the top of the stack when a function
call was entered<span class="note"><label for="fp-repr-machine" class="margin-toggle sidenote-number"></label></span><input type="checkbox" id="fp-repr-machine" class="margin-toggle" /><span class="sidenote">Typically, when targeting machine code, frame pointers are
stored in CPU registers.</span>.
When a function is entered, it can ask the runtime to reserve some space on the
stack that it will use for storing local variables. Then, those local values
can be accessed relative to an offset from the frame pointer.</p>
<details>
<summary>Example of compiling a function</summary>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class="language-id">ocaml</div><div class='code-container'><code><div class='line'><span style="color: #AF00DB">let</span><span style="color: #000000"> </span><span style="color: #795E26">f</span><span style="color: #000000"> </span><span style="color: #267F99">=</span><span style="color: #000000"> \x </span><span style="color: #811F3F">-&gt;</span></div><div class='line'><span style="color: #000000">  n </span><span style="color: #811F3F">=</span><span style="color: #000000"> </span><span style="color: #098658">1</span></div><div class='line'><span style="color: #000000">  m </span><span style="color: #811F3F">=</span><span style="color: #000000"> </span><span style="color: #098658">2</span></div><div class='line'><span style="color: #000000">  n </span><span style="color: #811F3F">+</span><span style="color: #000000"> m</span></div></code></div></pre>
<p>can compile to something like</p>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class='code-container'><code><div class='line'><span style="color: undefined">f:
  sp-add 2  # reserve two cells on the stack, for n and m.
            # n will live at fp[0], i.e. at the index of the frame pointer
            # m will live at fp[1]
  push 1
  store-into fp[0]  # push, store n=1
  push 2
  store-into fp[1]  # push, store m=2
  push fp[0]
  push fp[1]
  add
  ret</span></div></code></div></pre>
</details>
<h3 id="representing-function-calls" tabindex="-1"><a class="header-anchor" href="#representing-function-calls" aria-hidden="true"></a>Representing function calls</h3>
<p>Before calling a function, the caller needs to</p>
<ul>
<li>allocate space for the callee's return value</li>
<li>push on the callee's arguments<span class="note"><label for="push-args" class="margin-toggle sidenote-number"></label></span><input type="checkbox" id="push-args" class="margin-toggle" /><span class="sidenote">this includes any captured values, which will be discussed later</span></li>
<li>store the program counter of the caller (since this is global)</li>
<li>store the frame pointer of the caller (since this is global, and will be
modified in the new function frame)</li>
</ul>
<p>We can have the virtual machine runtime take care of storing the program counter
and frame pointer, and restoring them when a function is returned, but our
compiler will need to take care of the first two line items.</p>
<p>In all, the procedure for calling functions is:</p>
<ul>
<li>
<p>Before call entry:</p>
<ul>
<li>
<p>allocate space for the return value</p>
</li>
<li>
<p>push on the callee's arguments</p>
</li>
<li>
<details>
<summary>
push on the caller's program counter and frame pointer
</summary>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class='code-container'><code><div class='line'><span style="color: undefined">&lt;return value&gt;
arg1
...
argn
@caller_pc
@caller_fp
--- &lt; stack top</span></div></code></div></pre>
</details>
</li>
</ul>
</li>
<li>
<p>During call:</p>
<ul>
<li>
<details>
<summary>Set the new program counter and frame pointer for the callee</summary>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class='code-container'><code><div class='line'><span style="color: undefined">&lt;return value&gt;
arg1
...
argn
@caller_pc
@caller_fp
--- &lt; stack top = fp</span></div></code></div></pre>
</details>
</li>
</ul>
</li>
<li>
<p>Upon return:</p>
<ul>
<li>
<details>
<summary>Reset the top of the stack to the callee's frame pointer.
That means the caller's frame pointer is now the top value on the stack.</summary>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class='code-container'><code><div class='line'><span style="color: undefined">&lt;return value&gt;
arg1
...
argn
@caller_pc
@caller_fp
---        &lt; fp &lt;-------\
&lt;local args&gt;            |
&lt;other stuff&gt;           |
---        &lt; reset to --/</span></div></code></div></pre>
</details>
</li>
<li>
<details>
<summary>Pop and restore the caller's frame pointer and program
counter.</summary>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class='code-container'><code><div class='line'><span style="color: undefined">&lt;return value&gt;
arg1
...
argn       &lt; ----------\
@caller_pc             |
@caller_fp             |
---        &lt; reset to -/</span></div></code></div></pre>
</details>
</li>
<li>
<details>
<summary>The caller deallocates the provided arguments, leaving the return value on
  the top of the stack.</summary>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class='code-container'><code><div class='line'><span style="color: undefined">&lt;return value&gt; &lt;-------\
arg1                   |
...                    |
argn       &lt; reset to -/</span></div></code></div></pre>
</details>
</li>
</ul>
</li>
</ul>
<details>
<summary>Here's how a full function call would be represented in the VM.</summary>
<figure class="fullwidth notes-fullwidth resp-iframe-container" style="margin-top:2em;height:10vh">
  <iframe class="resp-iframe" src="https://ayazhafiz.com/plts/playground/co_lc/?input=DYUwLgBAhgJjAqBXADhAvBAOpAtAPgCgJiJRIBbdCMAOgAYIBLAOyJLImatoEYnWSESgGpOBFtDhJUAbwDMAGggBWAL5A&backend=ir&options=NohEFMFsEsBdQDQG9QDcCGAbAruUAuUABwCdoA7eBUAeyNmhvIGcDhizLEJN0AjUAF0AvoMEIwUOIhQYceQqQpVa9RizYdl3cLwEixgoA" allowtransparency="true" frameborder="0"></iframe>
</figure>
</details>
<h3 id="representing-fibers" tabindex="-1"><a class="header-anchor" href="#representing-fibers" aria-hidden="true"></a>Representing fibers</h3>
<p>In this model, each fiber is identified by a unique stack. Spawning a fiber
allocates a new call stack. The virtual machine needs to bookkeep</p>
<ul>
<li>each unique fiber's call stack</li>
<li>what the current stack of fibers is, relative to the main fiber</li>
</ul>
<p>Spawning or resuming a fiber pushes onto the stack of active fibers.
Yielding pops the current fiber off the top of the stack, leaving the yielded
fiber's representation on the parent fiber's stack, as the return value of the
matching <code>spawn</code> or <code>resume</code>.</p>
<p>Because our fibers cannot be resumed multiple times, we also need to keep track
of a dirty bit in both the runtime representation of a fiber's stack, and the
<code>Fiber</code> value we return to the parent fiber. When a fiber is resumed, we check
that its dirty bit lines up with the fiber's dirty bit state; if these values
are out-of-line, we know the fiber has already been resumed and can't be resumed
again.<span class="note"><label for="dirty-bit-unneeded" class="margin-toggle sidenote-number"></label></span><input type="checkbox" id="dirty-bit-unneeded" class="margin-toggle" /><span class="sidenote"> Note that the dirty bit would not needed if the type system were to enforce that a
fiber can be resumed at most once. It also would not be needed if multi-shot
resumptions were supported; one strategy to enable that is to create a new fiber
on each resumption, and reference-count fiber stacks.</span></p>
<p>Put all together, we can represent a <code>Fiber</code> that terminates with type <code>T</code> as
the runtime tuple</p>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class="language-id">ocaml</div><div class='code-container'><code><div class='line'><span style="color: #000000">{ bit: int, value: T, fibidx: int, fibdirty: int }</span></div></code></div></pre>
<p>Where <code>bit=1</code> when the fiber is done, and 0 otherwise; <code>value</code> is the value the
fiber terminated with, or else undefined; <code>fibidx</code> is the unique reference to
the fiber's call stack; <code>fibdirty</code> is the fiber's dirty bit.</p>
<p>The values in the runtime tuple cannot be accessed directly from our source
language. In fact, <code>fibidx</code> and <code>fibdirty</code> are purely implementation details.
<code>bit</code> and <code>value</code> can be accessed conditionally, via the <code>stat</code> keyword.</p>
<h3 id="representing-tuples" tabindex="-1"><a class="header-anchor" href="#representing-tuples" aria-hidden="true"></a>Representing tuples</h3>
<p>Speaking of <code>stat</code>, it's worth noting how tuples (including <code>Fiber</code>s) are
represented on the stack. The directionality is somewhat arbitrary, but here
we'll have lower-indexed elements in a tuple stored at the top of the stack. For
example, a <code>Fiber&lt;{int, int}&gt;</code> will be stored as</p>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class='code-container'><code><div class='line'><span style="color: undefined">fiber.fibdirty
fiber.fibidx
fiber.value.1
fiber.value.0
fiber.bit &lt; stack top</span></div></code></div></pre>
<p>This has the advantage of making <code>stat</code>'s job easier - once a fiber is loaded
onto the top of the stack, the pending/done bit can be immediately popped off,
and if needed, the terminating value is right on top of the stack.</p>
<h3 id="instruction-set" tabindex="-1"><a class="header-anchor" href="#instruction-set" aria-hidden="true"></a>Instruction set</h3>
<details style="margin-block-start: 1em">
<summary>
All that described, we can construct an instruction set for our virtual machine.
</summary>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class="language-id">ocaml</div><div class='code-container'><code><div class='line'><span style="color: #0000FF">type</span><span style="color: #000000"> </span><span style="color: #795E26">op</span><span style="color: #000000"> </span><span style="color: #267F99">=</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">Eq</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">Lt</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">Sub</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">Add</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">Mul</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">Yield</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">Spawn</span><span style="color: #000000"> </span><span style="color: #800000">of</span><span style="color: #000000"> </span><span style="color: #800000">{</span><span style="color: #000000"> </span><span style="color: #0451A5">proc</span><span style="color: #000000"> </span><span style="color: #811F3F">:</span><span style="color: #000000"> label</span><span style="color: #811F3F">;</span><span style="color: #000000"> </span><span style="color: #0451A5">args_size</span><span style="color: #000000"> </span><span style="color: #811F3F">:</span><span style="color: #000000"> int</span><span style="color: #811F3F">;</span><span style="color: #000000"> </span><span style="color: #0451A5">ret_size</span><span style="color: #000000"> </span><span style="color: #811F3F">:</span><span style="color: #000000"> int </span><span style="color: #800000">}</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">Resume</span><span style="color: #000000"> </span><span style="color: #800000">of</span><span style="color: #000000"> int  </span><span style="color: #811F3F">(** size of return value *)</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">Push</span><span style="color: #000000"> </span><span style="color: #800000">of</span><span style="color: #000000"> locator</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">Store</span><span style="color: #000000"> </span><span style="color: #800000">of</span><span style="color: #000000"> int  </span><span style="color: #811F3F">(** store-into fp[offset] *)</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">SpAdd</span><span style="color: #000000"> </span><span style="color: #800000">of</span><span style="color: #000000"> int</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">SpSub</span><span style="color: #000000"> </span><span style="color: #800000">of</span><span style="color: #000000"> int</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">SpRestoreFp</span><span style="color: #000000">  </span><span style="color: #811F3F">(** restore to the frame pointer. Used for tail calls *)</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">Jmp</span><span style="color: #000000"> </span><span style="color: #800000">of</span><span style="color: #000000"> label</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">Jmpz</span><span style="color: #000000"> </span><span style="color: #800000">of</span><span style="color: #000000"> label</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">Jmprel1</span><span style="color: #000000">  </span><span style="color: #811F3F">(** jump relative to 1 + the integer on the top of the stack. *)</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">Call</span><span style="color: #000000"> </span><span style="color: #800000">of</span><span style="color: #000000"> label</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">Ret</span></div><div class='line'></div><div class='line'><span style="color: #0000FF">type</span><span style="color: #000000"> </span><span style="color: #795E26">basic_block</span><span style="color: #000000"> </span><span style="color: #267F99">=</span><span style="color: #000000"> label </span><span style="color: #811F3F">*</span><span style="color: #000000"> op </span><span style="color: #795E26">list</span></div><div class='line'></div><div class='line'><span style="color: #0000FF">type</span><span style="color: #000000"> </span><span style="color: #795E26">proc</span><span style="color: #000000"> </span><span style="color: #267F99">=</span><span style="color: #000000"> </span><span style="color: #800000">{</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #0451A5">name</span><span style="color: #000000"> </span><span style="color: #811F3F">:</span><span style="color: #000000"> label</span><span style="color: #811F3F">;</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #0451A5">blocks</span><span style="color: #000000"> </span><span style="color: #811F3F">:</span><span style="color: #000000"> basic_block </span><span style="color: #795E26">list</span><span style="color: #811F3F">;</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #0451A5">debug_frame</span><span style="color: #000000"> </span><span style="color: #811F3F">:</span><span style="color: #000000"> debug_frame</span><span style="color: #811F3F">;</span></div><div class='line'><span style="color: #800000">}</span></div></code></div></pre>
</details>
<p>Instructions are organized into <a href="https://en.wikipedia.org/wiki/Basic_block">basic blocks</a>,
which are identified by a label and contain zero or more instructions that are
executed in a linear fashion. A basic block only branches out via a jump or
return at its exit.
Procedures consist of a name and one or more basic blocks.</p>
<p>Most of the bytecode instructions are standard, though there are a few
interesting ones:</p>
<ul>
<li>Along with taking the procedure to call, <code>Spawn</code> requires the size of the
procedure's arguments. That's because the arguments will need to be copied
over from the parent stack into the stack allocated for the child fiber.</li>
<li>Both <code>Spawn</code> and <code>Resume</code> require the size of the fiber's termination value,
because upon yield or termination, the runtime will need to know how
large to make the <code>Fiber</code> value representation.</li>
<li><code>SpAdd</code> allocates space on the stack (for local arguments and return values),
<code>SpSub</code> deallocates space on the stack (so callers can reclaim space used
for call argument), and <code>SpRestoreFp</code> restores the top of the stack to the
current frame pointer. We'll see that the latter instruction is useful for
implementing tail call elimination; it is otherwise unnecessary, since such
restoration happens by the runtime during a return.</li>
<li><code>Call</code> requires a named procedure, and there is no support for indirect calls.
This is not a joke, and there is no restiction here - we'll see below how to
compile <code>co_lc</code>, unrestricted in the kinds of closures you can create,
with only direct calls.</li>
</ul>
<h2 id="compilation-strategy" tabindex="-1"><a class="header-anchor" href="#compilation-strategy" aria-hidden="true"></a>Compilation strategy</h2>
<h3 id="type-inference" tabindex="-1"><a class="header-anchor" href="#type-inference" aria-hidden="true"></a>Type inference</h3>
<p>There are a few type systems <code>co_lc</code> could use; here we use the type system of
the simply-typed lambda calculus, with complete type inference via <a href="https://en.wikipedia.org/wiki/Unification_(computer_science)">unification</a>.
<a href="https://github.com/ayazhafiz/plts/blob/base/co_lc/ty_solve.ml">Here's one implementation of <code>co_lc</code> inference algorithm</a>;
I won't go into depth about it here, but the approach is pretty standard.</p>
<h4 id="a-tip-for-inference-of-tuples" tabindex="-1"><a class="header-anchor" href="#a-tip-for-inference-of-tuples" aria-hidden="true"></a>A tip for inference of tuples</h4>
<p>One thing that may be interesting, which I don't see typically covered in
discussions of unification-based inference, is how to deal with the inference of
tuples. The question has to do with an expression like</p>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class="language-id">ocaml</div><div class='code-container'><code><div class='line'><span style="color: #AF00DB">let</span><span style="color: #000000"> </span><span style="color: #795E26">f</span><span style="color: #000000"> </span><span style="color: #267F99">=</span><span style="color: #000000"> \t </span><span style="color: #811F3F">-&gt;</span></div><div class='line'><span style="color: #000000">  t</span><span style="color: #0000FF">.</span><span style="color: #000000">1 == 10</span></div></code></div></pre>
<p>Clearly, <code>t</code> is a tuple with an arity of at least two, where the second element
is an int. But the precise arity of the tuple, and its other elements' types,
cannot be well-known at this point.</p>
<p>One solution is to have both dense representations of tuple types (for when
a tuple literal is seen), and a sparse representation for cases like the both.
That is, our type definition might look like</p>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class="language-id">ocaml</div><div class='code-container'><code><div class='line'><span style="color: #0000FF">type</span><span style="color: #000000"> </span><span style="color: #795E26">ty</span><span style="color: #000000"> </span><span style="color: #267F99">=</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #811F3F">..</span><span style="color: #811F3F">.</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">TupleDense</span><span style="color: #000000"> </span><span style="color: #800000">of</span><span style="color: #000000"> ty </span><span style="color: #795E26">list</span><span style="color: #000000">  </span><span style="color: #811F3F">(*</span><span style="color: #811F3F"> list of element types </span><span style="color: #811F3F">*)</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #267F99">|</span><span style="color: #000000"> </span><span style="color: #800000">TupleSparse</span><span style="color: #000000"> </span><span style="color: #800000">of</span><span style="color: #000000"> </span><span style="color: #800000">(</span><span style="color: #000000">int </span><span style="color: #811F3F">*</span><span style="color: #000000"> ty</span><span style="color: #800000">)</span><span style="color: #000000"> </span><span style="color: #795E26">list</span><span style="color: #000000">  </span><span style="color: #811F3F">(*</span><span style="color: #811F3F"> list of known indices' types </span><span style="color: #811F3F">*)</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #811F3F">...</span></div></code></div></pre>
<p>When a <code>TupleSparse</code> unifies with a <code>TupleDense</code>, its respective elements (and
arities) must unify, and then the <code>TupleSparse</code> must become a <code>TupleDense</code>,
since that is the point of the concrete type's instantiation.</p>
<h3 id="eliminating-indirect-calls-and-heap-allocated-closures-via-defunctionalization" tabindex="-1"><a class="header-anchor" href="#eliminating-indirect-calls-and-heap-allocated-closures-via-defunctionalization" aria-hidden="true"></a>Eliminating indirect calls and heap-allocated closures via defunctionalization</h3>
<p>I did promise no indirect function calls, and I must deliver. We'll use
type-directed defunctionalization, via <strong>lambda sets</strong>, to guarantee that
all calls can be compiled directly<span class="note"><label for="defunctionalization-opt" class="margin-toggle sidenote-number"></label></span><input type="checkbox" id="defunctionalization-opt" class="margin-toggle" /><span class="sidenote">Defunctionalization (and <a href="https://quuxplusone.github.io/blog/2021/02/15/devirtualization/">devirtualization</a>) are typically done as optimizations in later stages of a compiler; however, by embedding call information in the type system, we can guarantee the optimization is applied.</span>,
with conditional dispatch via a jump table rather than a function pointer.</p>
<p>Lambda sets are due to William Brandon, et.al., unpublished manuscript. Lambda
sets are also used in <a href="https://www.roc-lang.org">Roc</a> to compile closures
without indirect calls or heap allocation.</p>
<h4 id="why-does-eliminating-indirect-calls-matter%3F" tabindex="-1"><a class="header-anchor" href="#why-does-eliminating-indirect-calls-matter%3F" aria-hidden="true"></a>Why does eliminating indirect calls matter?</h4>
<p>An indirect call occurs when a machine has to load the address to call at
runtime, rather than it being statically known.</p>
<h5 id="function-pointers" tabindex="-1"><a class="header-anchor" href="#function-pointers" aria-hidden="true"></a>Function pointers</h5>
<p>In our source language, it's reasonable to write something like</p>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class="language-id">ocaml</div><div class='code-container'><code><div class='line'><span style="color: #AF00DB">let</span><span style="color: #000000"> </span><span style="color: #795E26">caller</span><span style="color: #000000"> </span><span style="color: #267F99">=</span><span style="color: #000000"> \f </span><span style="color: #811F3F">-&gt;</span><span style="color: #000000"> f </span><span style="color: #098658">1</span><span style="color: #000000"> in</span></div><div class='line'><span style="color: #AF00DB">let</span><span style="color: #000000"> </span><span style="color: #795E26">id</span><span style="color: #000000"> </span><span style="color: #267F99">=</span><span style="color: #000000"> \x </span><span style="color: #811F3F">-&gt;</span><span style="color: #000000"> x in</span></div><div class='line'><span style="color: #000000">caller id</span></div></code></div></pre>
<p>A direct compilation of this code might produce bytecode like</p>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class='code-container'><code><div class='line'><span style="color: undefined">id:
  ...
caller:
  # suppose the argument is at fp[-3]
  push 1
  push fp[-3]
  call-indirect
  ret
main:
  push &id
  call caller
  ret</span></div></code></div></pre>
<p>where the address of the function passed to <code>caller</code> has to be loaded, popped,
and dereferenced at runtime in order for <code>call-indirect</code> to determine what
function should ultimately be called. It's clear that in a program like the one
above, a smarter analysis could reduce the compiled code to</p>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class='code-container'><code><div class='line'><span style="color: undefined">id:
  ...
caller:
  push 1
  call id
  ret
main:
  call caller
  ret</span></div></code></div></pre>
<p>The advantages of the latter include</p>
<ul>
<li>The call site is statically known, enabling further compiler analyses and
optimizations like inlining <code>id</code> in <code>caller</code>.</li>
<li>If this were compiled to target a CPU, there would be no reliance on the CPU's
branch target predictor at runtime.</li>
</ul>
<p>The biggest downside of this approach I'm aware of is that if <code>caller</code> is called
with multiple times with unique functions,</p>
<ul>
<li>a unique copy of <code>caller</code> must be stamped out for each unique argument (monomorphization, increasing code size)</li>
<li>or, direct calls can be used, but must be guarded by a jump table</li>
</ul>
<p>Speaking of jump tables -</p>
<h5 id="conditionally-determined-functions" tabindex="-1"><a class="header-anchor" href="#conditionally-determined-functions" aria-hidden="true"></a>Conditionally-determined functions</h5>
<p>A second case has to do with the representation conditionally-determined
functions. Let's extend our previous example to</p>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class="language-id">ocaml</div><div class='code-container'><code><div class='line'><span style="color: #AF00DB">let</span><span style="color: #000000"> </span><span style="color: #795E26">caller</span><span style="color: #000000"> </span><span style="color: #267F99">=</span><span style="color: #000000"> \f </span><span style="color: #811F3F">-&gt;</span><span style="color: #000000"> f </span><span style="color: #098658">1</span><span style="color: #000000"> in</span></div><div class='line'></div><div class='line'><span style="color: #AF00DB">let</span><span style="color: #000000"> </span><span style="color: #795E26">id</span><span style="color: #000000"> </span><span style="color: #267F99">=</span><span style="color: #000000"> \x </span><span style="color: #811F3F">-&gt;</span><span style="color: #000000"> x in</span></div><div class='line'><span style="color: #AF00DB">let</span><span style="color: #000000"> </span><span style="color: #795E26">mul2</span><span style="color: #000000"> </span><span style="color: #267F99">=</span><span style="color: #000000"> \x </span><span style="color: #811F3F">-&gt;</span><span style="color: #000000"> x </span><span style="color: #811F3F">*</span><span style="color: #000000"> </span><span style="color: #098658">2</span></div><div class='line'><span style="color: #000000">caller </span><span style="color: #800000">(</span><span style="color: #AF00DB">if</span><span style="color: #000000"> </span><span style="color: #098658">0</span><span style="color: #000000"> </span><span style="color: #811F3F">==</span><span style="color: #000000"> </span><span style="color: #098658">0</span><span style="color: #000000"> </span><span style="color: #AF00DB">then</span><span style="color: #000000"> id </span><span style="color: #AF00DB">else</span><span style="color: #000000"> mul2</span><span style="color: #800000">)</span></div></code></div></pre>
<p>Again, a direct compilation of this code might produce bytecode like</p>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class='code-container'><code><div class='line'><span style="color: undefined">id:
  ...
caller:
  # suppose the argument is at fp[-3]
  push 1
  push fp[-3]
  call-indirect
main:
  push 0
  ifz
  jmp else
then:
  push &id
  call caller
  ret
else:
  push &mul
  call caller
  ret</span></div></code></div></pre>
<p>As before, this compilation determines a function pointer to dispatch to, and
passes that into <code>caller</code>. An alternative is to push down the conditional into
the body of <code>caller</code>, enabling a direct call within each branch of the
conditional.</p>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class='code-container'><code><div class='line'><span style="color: undefined">id:
  ...
caller:
  push 1
  # suppose the argument is at fp[-3]
  push fp[-3]
  ifz
  jmp call_mul_
call_id_:
  call id
  ret
call_mul_:
  call mul
  ret
main:
  push 0
  call caller
  ret</span></div></code></div></pre>
<p>The advantage here is that we've eliminated one source of indirection - we still
need a conditional, but as before, there are no more function pointers. This
may make inline analyses more fruitful, and places less pressure on a CPU's
branch target predictor.</p>
<p>One thing I'm not sure about is the efficacy of the latter <code>caller</code>
implementation relative to the former when <code>caller</code>'s argument is static. In
that case, the main performance consideration would be</p>
<ul>
<li>for the former <code>caller</code>, how long a dereference takes, and how well
branch target prediction works on a CPU</li>
<li>for the latter <code>caller</code>, how long a conditional and jump takes, and how well
branch prediction works on a CPU</li>
</ul>
<p>I am not aware of any empirical studies on the efficacy of CPU's branch predictors
vs their branch target predictors<span class="note"><label for="branch-predictor-cf" class="margin-toggle sidenote-number"></label></span><input type="checkbox" id="branch-predictor-cf" class="margin-toggle" /><span class="sidenote">Though,
there is <a href="https://blog.cloudflare.com/branch-predictor/">this nice analysis by Cloudflare</a>.</span> -
<a href="mailto:ayaz.hafiz.1+co_lc@gmail.com?subject=Efficacy%20of%20branch%20target%20predictors%20vs%20branch%20predictors">please let me know</a> if you know of any!</p>
<h4 id="eliminating-heap-allocated-captures" tabindex="-1"><a class="header-anchor" href="#eliminating-heap-allocated-captures" aria-hidden="true"></a>Eliminating heap-allocated captures</h4>
<p>We'll see that lambda sets also yield a natural way to eliminate the heap
allocation of closure captures. This is pretty nice, especially in functional
languages where closures are common, and are often determined conditionally.</p>
<p>Let's consider the program</p>
<figure class="fullwidth notes-fullwidth resp-iframe-container" style="margin-top:2em;height:10vh">
  <iframe class="resp-iframe" src="https://ayazhafiz.com/plts/playground/co_lc/?input=DYUwLgBAHhC8EFYIEsB2FSQJ5wgNhXUwgC9cB2QgKGIDNcAddAWgD4qIV71Z4BGDhDAALEOgYB3CGwhSA1NEEhgAZxCDOybnHgAmDUNHipM%2BdAgKsB5WoiTprWRfOXnJKmioBvenwi6AGgh6XX8g%2BgBmCAiAXyA&backend=ir&options=NohEFMFsEsBdQDQG9QDcCGAbAruUAuUABwCdoA7eBUAeyNmhvIGcDhizLEJN0AjUAF0AvoMEIwUOIhQYceQqQpVa9RizYdl3cLwEixgoA" allowtransparency="true" frameborder="0"></iframe>
</figure>
<p>where <code>f</code> returns a function that either captures <code>x</code>, <code>x</code> and <code>y</code>, or <code>x</code> and
<code>y</code> and <code>z</code> (notice that <code>f</code> itself must capture all three). At runtime, the
captures must live alongside the representation of the function to call - which
means that the runtime representation of the captures must also be the same
size, no matter what function is returned<span class="note"><label for="captures-same-sized" class="margin-toggle sidenote-number"></label></span><input type="checkbox" id="captures-same-sized" class="margin-toggle" /><span class="sidenote">Because the return
value of <code>f</code> can be used indiscriminately, including being passed around to arbitrary
locations, it must have a statically-known size.</span>.</p>
<p>The typical way this requirement of uniformity<span class="note"><label for="conditional-closure" class="margin-toggle sidenote-number"></label></span><input type="checkbox" id="conditional-closure" class="margin-toggle" /><span class="sidenote">Of course, one
alternative is to disallow the conditional selection of a closure. C++ and Rust
enforce this restriction by giving each closure a unique type, which is
incompatible with every other closure type.</span>
is achieved is by compiling closures to a representation like the following C struct</p>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class="language-id">c</div><div class='code-container'><code><div class='line'><span style="color: #0000FF">struct</span><span style="color: #000000"> closure {</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #0000FF">void</span><span style="color: #000000">* fn_addr;</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #0000FF">void</span><span style="color: #000000">* captures;</span></div><div class='line'><span style="color: #000000">};</span></div></code></div></pre>
<p>where each capturing function takes an opaque <code>captures</code> pointer as an argument,
which it can then unpack to the concrete type of captures it knows.</p>
<p>For the function <code>f</code> returns, this is needlessly generic - <code>f</code>'s returned closure
can have the stricter representation</p>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class="language-id">c</div><div class='code-container'><code><div class='line'><span style="color: #0000FF">struct</span><span style="color: #000000"> f_closure {</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #0000FF">int</span><span style="color: #000000"> tag; </span><span style="color: #008000">// 1, 2, or 3</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #0000FF">struct</span><span style="color: #000000"> f_closure_captures captures;</span></div><div class='line'><span style="color: #000000">};</span></div><div class='line'></div><div class='line'><span style="color: #0000FF">union</span><span style="color: #000000"> f_closure_captures {</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #0000FF">struct</span><span style="color: #000000"> captures1;</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #0000FF">struct</span><span style="color: #000000"> captures2;</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #0000FF">struct</span><span style="color: #000000"> captures3;</span></div><div class='line'><span style="color: #000000">};</span></div><div class='line'></div><div class='line'><span style="color: #0000FF">struct</span><span style="color: #000000"> captures1 {</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #0000FF">int</span><span style="color: #000000"> x;</span></div><div class='line'><span style="color: #000000">};</span></div><div class='line'><span style="color: #0000FF">struct</span><span style="color: #000000"> captures2 {</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #0000FF">int</span><span style="color: #000000"> x; </span><span style="color: #0000FF">int</span><span style="color: #000000"> y;</span></div><div class='line'><span style="color: #000000">};</span></div><div class='line'><span style="color: #0000FF">struct</span><span style="color: #000000"> captures3 {</span></div><div class='line'><span style="color: #000000">  </span><span style="color: #0000FF">int</span><span style="color: #000000"> x; </span><span style="color: #0000FF">int</span><span style="color: #000000"> y; </span><span style="color: #0000FF">int</span><span style="color: #000000"> z;</span></div><div class='line'><span style="color: #000000">};</span></div></code></div></pre>
<p>That is, we can keep a tag of three states telling us which function to dispatch
to (this is the elimination of function pointers discussed in previous
sections). And, we can reduce the representation of captures to a three-state
union - which can all be stored on the stack, at the expense of paying for the
largest captures size!</p>
<p>As before, we are making tradeoffs here. While this helps avoid heap-allocation,
it means that</p>
<ul>
<li>The smallest captures in a representation like the above take as much space on
the stack as the largest captures, which can be exceptionally wasteful if
the size discrepancy is large.</li>
<li>This scheme makes incremental and separate compilation more challenging, as
the addition of a new function can change the memory representation of
values far away.</li>
</ul>
<h4 id="inference-and-compilation-semantics-of-lambda-sets" tabindex="-1"><a class="header-anchor" href="#inference-and-compilation-semantics-of-lambda-sets" aria-hidden="true"></a>Inference and compilation semantics of lambda sets</h4>
<p>Actually, the <code>f_closure</code> struct representation I gave above is exactly where
lambda sets take us! If you already see how to get there, feel free to skip this
section.</p>
<p>I must again say that the original idea of lambda sets in this type-directed
form is due to William Brandon, et.al. in an unpublished manuscript. We've also
used them in Roc, and learned a lot about their behavior (many potential blog
posts about that!).</p>
<p>The idea is</p>
<ul>
<li>
<p>Each syntactic function (a lambda <code>\x -&gt; ...</code>) gets a unique name</p>
</li>
<li>
<p>When inferring the type of a function, include the name of that function and
its set of captures in a set adjacent to the function type; this is the
lambda set.
For example,</p>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class="language-id">ocaml</div><div class='code-container'><code><div class='line'><span style="color: #000000">x = 1</span></div><div class='line'><span style="color: #000000">y = 1</span></div><div class='line'><span style="color: #000000">f = \n -&gt; n + x + y</span></div></code></div></pre>
<p>may be given type <code>int -[f {x: int, y: int}]-&gt; int</code>, where <code>[f {x: int, y: int}]</code> is the lambda set.</p>
</li>
<li>
<p>When two functions unify, their lambda sets union.</p>
</li>
</ul>
<p>Take a look at the inferred types of our example from above. Feel free to
hover over <code>f</code>, or look at the elaborated output.</p>
<figure class="fullwidth notes-fullwidth resp-iframe-container" style="margin-top:2em;height:10vh">
  <iframe class="resp-iframe" src="https://ayazhafiz.com/plts/playground/co_lc/?input=DYUwLgBAHhC8EFYIEsB2FSQJ5wgNhXUwgC9cB2QgKGIDNcAddAWgD4qBiCbgPSu%2BT10seAEZ%2BEMAAsQ6BgHcIbCIoDU0CSGABnEBIFC48AEz7JMuYuVroEdVjNbdEBUtYq7t%2B55JU0VAG96UQhjABoIemNQiPoAZgg4gF8gA&backend=solve&options=NohEFMFsEsBdQDQG9QDcCGAbAruUAuCTdAI0VAHsAHWaCgOwGcDhQqAnae%2BBI00ALoBfAQIRgocRCgw48hDlx6UadJizadu5cMTLDRAoA" allowtransparency="true" frameborder="0"></iframe>
</figure>
<p>Notice that the inferred type is saying that <code>f</code> returns a function of type <code>int -&gt; int</code> whose lambda set is <code>[lam {x} | lam1 {x, y} | lam2 {x, y, z}]</code> - exactly
the three functions that we might dispatch to, and what their captures are! This
is all we need in order to compile the return value of <code>f</code> to the
<code>f_closure</code>-like representation described previously.</p>
<h3 id="compiling-functions%2C-including-lambda-sets" tabindex="-1"><a class="header-anchor" href="#compiling-functions%2C-including-lambda-sets" aria-hidden="true"></a>Compiling functions, including lambda sets</h3>
<details style="margin-block-start: 1em">
<summary>
Put all together, our compilation scheme for functions consists of
</summary>
<figure class="fullwidth notes-fullwidth resp-iframe-container" style="margin-top:2em;height:10vh">
  <iframe class="resp-iframe" src="https://ayazhafiz.com/plts/playground/co_lc/?input=DYUwLgBAHhC8EFYIEsB2FSQJ5wgNhXUwgC9cB2QgKGIDNcAddAWgD4qIV71Z4BGDhDAALEOgYB3CGwhSA1NEEhgAZxCDOybnHgAmDUNHipM%2BdAgKsB5WoiTprWRfOXnJKmioBvenwi6AGgh6XX8g%2BgBmCAiAXyA&backend=ir&options=NohEFMFsEsBdQDQG9QDcCGAbAruUAuUABwCdoA7eBUAeyNmhvIGcDhizLEJN0AjUAF0AvoMEIwUOIhQYceQqQpVa9RizYdl3cLwEixgoA" allowtransparency="true" frameborder="0"></iframe>
</figure>
</details>
<ul>
<li>When compiling a function (e.g. <code>lam2</code> of the example above)
<ul>
<li>Determine the stack size of its captures based on the largest captures of
any lambda in the lambda set it's involved in.
<ul>
<li>Compile the function to unpack the passed captures appropriately.</li>
<li>For the runtime representation of the function-to-call, store the captures on the
stack.</li>
</ul>
</li>
<li>If the lambda set of the function is non-unary, the function to call must be
determined conditionally; store a tag for this function on the top of the
stack (e.g. <code>2</code>, since <code>lam2</code> appears in index 2 of the set).</li>
</ul>
</li>
<li>When calling a function
<ul>
<li>
<details>
<summary>Load the argument, then the function. That way, the stack consists of the
  argument, followed by any captures, followed by optionally the function
  tag on the top of the stack.</summary>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class='code-container'><code><div class='line'><span style="color: undefined">&lt;arg&gt;
&lt;captures&gt;
&lt;tag if non-unary lambda set&gt;   &lt; stack top</span></div></code></div></pre>
</details>
</li>
<li>
<p>If the lambda set is unary, there is only one function that can be called -
compile the direct call.</p>
</li>
<li>
<p>If the lambda set is non-unary, build a <a href="https://stackoverflow.com/questions/48017/what-is-a-jump-table">jump table</a> (<a href="https://github.com/ayazhafiz/plts/blob/618c11248c41766be0a62d560b53fa9ce40a0040/co_lc/vm_conv.ml#L656-L682">one implementation</a>)
using the integer tag of the lambda on the top of the stack. Each branch of
the jump table can perform the appropriate direct call to the matched
function.</p>
</li>
</ul>
</li>
</ul>
<h3 id="tip%3A-deciding-where-to-store-values" tabindex="-1"><a class="header-anchor" href="#tip%3A-deciding-where-to-store-values" aria-hidden="true"></a>Tip: deciding where to store values</h3>
<p>I don't know if this is well-known, but one thing I find helpful during
compilation is to have the procedure that compiles an expression take a
parameter indicating where the expression should be compiled, rather than
(in this case) always compiling to the stack and storing the result elsewhere
later. This eliminates a lot of trivially-reducable load and stores.</p>
<p>For example, <a href="https://github.com/ayazhafiz/plts/blob/618c11248c41766be0a62d560b53fa9ce40a0040/co_lc/vm_conv.ml#L530">my implementation</a>
has the recursive bytecode compiler take an optional target destination, which
looks like</p>
<pre class="shiki light-plus" style="background-color: #FFFFFF; color: #000000"><div class="language-id">ocaml</div><div class='code-container'><code><div class='line'><span style="color: #0000FF">type</span><span style="color: #000000"> </span><span style="color: #795E26">opt_target</span><span style="color: #000000"> </span><span style="color: #267F99">=</span></div><div class='line'><span style="color: #000000">  [ `Any</span></div><div class='line'><span style="color: #000000">  | `FpOffset of int  (** store as a local offset from the frame pointer *)</span></div><div class='line'><span style="color: #000000">  | `Stack (** store on the top of the stack *) ]</span></div></code></div></pre>
<p>Sometimes, the target truly can be arbitrary. For example, when <a href="https://github.com/ayazhafiz/plts/blob/618c11248c41766be0a62d560b53fa9ce40a0040/co_lc/vm_conv.ml#L736-L738">compiling a
tuple access</a>,
we don't really care if the tuple is loaded onto the top of stack or is in an
offset from the frame pointer - in the former case we can pop values off until
we get to the field we're looking for, and in the latter case, the access can be
made relative to where the tuple lives.</p>
<p>To facilitate the arbitrary-target case, the procedure also returns where
exactly the expression ended up being stored, as a type that's <code>opt_target</code>
without the <code>Any</code> variant.</p>
<h4 id="tail-call-optimization" tabindex="-1"><a class="header-anchor" href="#tail-call-optimization" aria-hidden="true"></a>Tail-call optimization</h4>
<p>Passing an optional target makes tail-call optimization very natural - when
we're compiling a function, we set up the target of the function body to a
special <code>return</code> local, which is the location where the caller allocated space
for the return value.</p>
<p>During the compilation of a function, if we see a call to the same function, and
whose target is the <code>return</code> local, we know that we can perform a tail-call
optimization! Thanks to lambda sets, the destination of a function call is in the function
type, so only the type of the function being applied needs to be examined to
understand <a href="https://github.com/ayazhafiz/plts/blob/618c11248c41766be0a62d560b53fa9ce40a0040/co_lc/vm_conv.ml#L609-L614">whether the optimization can be made</a>.</p>
<p>To actually perform the optimization, compile the call argument into the
location of the argument in the current function frame, reset the stack pointer
to the frame pointer, and jump back up to the top of the function. See, I
promised a use of <code>SpRestoreFp</code>!</p>
<h2 id="unexplored-extensions" tabindex="-1"><a class="header-anchor" href="#unexplored-extensions" aria-hidden="true"></a>Unexplored extensions</h2>
<p>Thanks for making it this far! You must be pretty interested in this kind of
stuff. There are various natural extensions to this project, which may make for
interesting projects:</p>
<ul>
<li>Make these fibers do something interesting. Our language and compiler is
enough to show off that the implementation of fibers works, but doesn't
actually demonstrate its use in an interesting one. One idea would be to add
support for making non-blocking network requests and show an example of
cooperative multitasking where multiple fibers fetch many webpages.</li>
<li>Implement an affine type system to enforce the one-shot behavior of our fibers
at compile-time.</li>
<li>Design and implement an analysis to detect what spawned expressions will never
yield. Those expressions can be optimized to happen as direct evaluations,
rather than needing to happen on a child fiber.</li>
<li>Design an efficient scheme for multi-resumable fibers.</li>
<li>Design a system for implicitly-yielding userland threads, and a preempting
runtime scheduler of userland threads. Modify the VM and compiler to support
this system.</li>
<li>Implement additional optimizations over the virtual machine, and optimizations
of the bytecode in the compiler.</li>
<li>My virtual machine is implemented in OCaml (and compiled to JavaScript via JSOO).
Using a tighter language, like C/Rust/Zig/whatever, for the VM (and compiling
to WASM) may result in a much faster machine.</li>
</ul>
<h2 id="playground-%26-implementation" tabindex="-1"><a class="header-anchor" href="#playground-%26-implementation" aria-hidden="true"></a>Playground &amp; Implementation</h2>
<p>I hope you enjoyed this post, and learned something. You can find my implementation
of the language compiler and VM on <a href="https://github.com/ayazhafiz/plts/tree/base/co_lc">GitHub</a>.
As you saw previously in this post, I've also made a <a href="https://ayazhafiz.com/plts/playground/co_lc/?input=DYUwLgBATiDGEDMCWAjCBeCAdAdhAtAHwBQEEAnkiMACYDcpESCEeAPBAEyNgAWIeHI2oBnEBAAUyNBLz4IARgCUSiAGpJ0yXK4riSIcVCQY8EAA84GbCLABDMOKKNbDiK8cA6AAyMAPhAABgAKAjQGAOYEJGRkxoioCtYwIgCuALbiHiA%2BTEKxEBZWAN7SCgA0EN6V2Z6c6ooAvv5BACIA9jjicoQQxbXVrDX2XpzNBkbg0Kk4AGKo1iIADnYA7nhSC5zeqhPxKanAkJhF8MVQM-MolYPejXnExADEXN44fAkonXawsEisGRQICglRwgOBEHaLAO6SWYCQnRExHOIDSR08FWgqMOYDqjSAA&amp;backend=ir&amp;options=NohEFMFsEsBdQDQG9QDcCGAbAruUAuUABwCdoA7eBUAeyNmhvIGcDhizLEJN0AjUAF0AvoMEIwUOIhQYceQqQpVa9RizYdl3cLwEixgoA">playground</a> for the
language, embdded again below.</p>
<figure class="fullwidth notes-fullwidth resp-iframe-container" style="margin-top:2em;height:10vh">
  <iframe class="resp-iframe" src="https://ayazhafiz.com/plts/playground/co_lc/?input=DYUwLgBATiDGEDMCWAjCBeCAdAdhAtAHwBQEEAnkiMACYDcpESCEeAPBAEyNgAWIeHI2oBnEBAAUyNBLz4IARgCUSiAGpJ0yXK4riSIcVCQY8EAA84GbCLABDMOKKNbDiK8cA6AAyMAPhAABgAKAjQGAOYEJGRkxoioCtYwIgCuALbiHiA%2BTEKxEBZWAN7SCgA0EN6V2Z6c6ooAvv5BACIA9jjicoQQxbXVrDX2XpzNBkbg0Kk4AGKo1iIADnYA7nhSC5zeqhPxKanAkJhF8MVQM-MolYPejXnExADEXN44fAkonXawsEisGRQICglRwgOBEHaLAO6SWYCQnRExHOIDSR08FWgqMOYDqjSAA&backend=ir&options=NohEFMFsEsBdQDQG9QDcCGAbAruUAuUABwCdoA7eBUAeyNmhvIGcDhizLEJN0AjUAF0AvoMEIwUOIhQYceQqQpVa9RizYdl3cLwEixgoA" allowtransparency="true" frameborder="0"></iframe>
</figure>
<h2 id="ad%3A-are-you-interested-in-compiling-structural-subtypes%3F" tabindex="-1"><a class="header-anchor" href="#ad%3A-are-you-interested-in-compiling-structural-subtypes%3F" aria-hidden="true"></a>Ad: Are you interested in compiling structural subtypes?</h2>
<p>If you know of ways, or are interested in, compiling languages based on
structural subtyping to non-uniform representations,
please <a href="mailto:ayaz.hafiz.1+co_lc@gmail.com?subject=Compiling%20structural%20subtyping%20to%20non-uniform%20representations">email me</a>! This has been an ongoing project of mine
and I hope to write about it soon, and would love to chat through with others
interested.</p>
<p>In particular, the idea here is to combine</p>
<ul>
<li>the programming flexibility of structural subtyping</li>
<li>(non-principal, possibly incomplete) type inference, a-la MLsub</li>
<li>row polymorphism and polymorphic variants</li>
</ul>
<p>to design subtyping-based source languages with compilation to target languages
that</p>
<ul>
<li>do not support runtime object polymorphism (i.e. all procedures are monomorphized)</li>
<li>have non-uniform, unboxed representations</li>
<li>do not require introducing implicit conversions at re-binding or usage sites</li>
</ul>


</article>

<section class="footer">
  
  <a href="/articles/22/simple-flow-refinement-of-anonymous-sum-types"
    >&laquo; Simple Refinement of Anonymous Sum Types in Pattern Matches</a
  >
  
  <span
    ><img class='emoji' alt='printer' src='https://gitlab.com/ayazhafiz/emoji-img/raw/master/public/emoji/unicode/1f5a8.png' height=20 width=20></img>&emsp;
    <span
      >&#8203;
      <script type="math/tex">
        \left[x^2 + y^2 + (x+y)^2 \right]^2 = 2\left[ x^4 + y^3 + (x+y)^4 \right]
      </script></span
    >
  </span>
  
</section>

<script src="https://utteranc.es/client.js"
        repo="ayazhafiz/gww-utterances"
        issue-term="title"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>

<script type="text/javascript">
  function $(query) {
    return document.querySelector(query);
  }

  function $$(query) {
    return Array.from(document.querySelectorAll(query));
  }

  function isFullWidth() {
    return $(".post").classList.contains("full");
  }

  function toggleFullWidth() {
    const isFull = isFullWidth();
    isFull
      ? $(".post").classList.remove("full")
      : $(".post").classList.add("full");
    toggleShowHideNotes(!isFull);
    toggleShowHideNotesSwitch(!isFull);
    return !isFull;
  }

  function toggleShowHideNotes(isFullWidth) {
    const notes = $$(".marginnote").concat($$(".sidenote"));
    notes.forEach(note => {
      isFullWidth
        ? note.classList.add("maybe-hide")
        : note.classList.remove("maybe-hide");
    });
  }

  document.addEventListener("DOMContentLoaded", () => {
    $$(".note").forEach(toggle =>
      toggle.addEventListener("click", () => {
        if (isFullWidth()) {
          toggleFullWidth();
        }
      })
    );
  });
</script>

        </div>
      </div>
    </div>

    <div class="bottom-bar">
    <details>
  <summary>Analytics</summary>
  By visiting this site, you agree to its use of <a href="https://www.cloudflare.com/analytics/"
    >Cloudflare Analytics</a
  >. No identifiable information is transmitted to Cloudflare. See
  <a href="https://www.cloudflare.com/web-analytics/">Cloudflare Analytics user privacy</a>.
</details>

</details>

    </div>
  </body>
</html>
